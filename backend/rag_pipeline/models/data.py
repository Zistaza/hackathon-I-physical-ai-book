from pydantic import BaseModel, Field, validator
from typing import List, Optional, Dict, Any
from datetime import datetime
import hashlib


class ContentChunk(BaseModel):
    """
    A segment of text extracted from the Docusaurus website with associated metadata
    """
    id: str = Field(description="Unique identifier for the chunk (hash of source_url + content)")
    content: str = Field(description="The actual text content of the chunk")
    source_url: str = Field(description="The URL from which this content was extracted")
    module: Optional[str] = Field(default=None, description="Module/chapter identifier from the source")
    chunk_index: int = Field(ge=0, description="Sequential index of this chunk within the source document")
    created_at: datetime = Field(default_factory=datetime.now, description="Timestamp when the chunk was created")
    content_hash: str = Field(description="Hash of the content for idempotency checks")

    @validator('content')
    def validate_content(cls, v):
        """Validate that content is not empty"""
        if not v.strip():
            raise ValueError('Content must not be empty')
        return v

    @validator('source_url')
    def validate_source_url(cls, v):
        """Validate that source_url is a valid URL format"""
        import re
        url_pattern = re.compile(
            r'^https?://'  # http:// or https://
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
            r'localhost|'  # localhost...
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
            r'(?::\d+)?'  # optional port
            r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        if not url_pattern.match(v):
            raise ValueError(f'Invalid URL format: {v}')
        return v

    @validator('chunk_index')
    def validate_chunk_index(cls, v):
        """Validate that chunk_index is non-negative"""
        if v < 0:
            raise ValueError('Chunk index must be non-negative')
        return v

    def __init__(self, **data):
        super().__init__(**data)
        # Generate ID if not provided, based on source_url and content
        if not self.id:
            self.id = self._generate_id()
        # Generate content hash if not provided
        if not self.content_hash:
            self.content_hash = self._generate_content_hash()

    def _generate_id(self) -> str:
        """Generate unique ID based on source_url and content"""
        content_to_hash = f"{self.source_url}{self.content}{self.chunk_index}"
        return hashlib.sha256(content_to_hash.encode()).hexdigest()

    def _generate_content_hash(self) -> str:
        """Generate hash of the content for idempotency checks"""
        return hashlib.sha256(self.content.encode()).hexdigest()


class EmbeddingVector(BaseModel):
    """
    A numerical representation of text content generated by Cohere models
    """
    chunk_id: str = Field(description="Reference to the ContentChunk this embedding represents")
    vector: List[float] = Field(description="The embedding vector (numerical representation)")
    model_name: str = Field(description="Name of the model used to generate the embedding")
    model_version: Optional[str] = Field(default=None, description="Version of the model used")
    created_at: datetime = Field(default_factory=datetime.now, description="Timestamp when the embedding was generated")

    @validator('vector')
    def validate_vector(cls, v):
        """Validate that vector has consistent dimensions"""
        if not v or len(v) == 0:
            raise ValueError('Vector must not be empty')
        # Check that all elements are numbers
        for item in v:
            if not isinstance(item, (int, float)):
                raise ValueError('Vector must contain only numeric values')
        return v

    @validator('chunk_id')
    def validate_chunk_id(cls, v):
        """Validate that chunk_id is not empty"""
        if not v:
            raise ValueError('Chunk ID must not be empty')
        return v


class ProcessingResult(BaseModel):
    """
    Result of a pipeline processing operation
    """
    id: str = Field(description="Unique identifier for this processing result")
    status: str = Field(description="Status of the processing (success, failed, partial)")
    processed_chunks_count: int = Field(ge=0, description="Number of chunks successfully processed")
    failed_chunks_count: int = Field(ge=0, description="Number of chunks that failed processing")
    start_time: datetime = Field(description="When processing started")
    end_time: datetime = Field(description="When processing completed")
    error_details: Optional[str] = Field(default=None, description="Details about any errors that occurred")

    @validator('status')
    def validate_status(cls, v):
        """Validate that status is one of the allowed values"""
        allowed_statuses = ["success", "failed", "partial"]
        if v not in allowed_statuses:
            raise ValueError(f'Status must be one of: {allowed_statuses}')
        return v

    @validator('processed_chunks_count', 'failed_chunks_count')
    def validate_counts(cls, v):
        """Validate that counts are non-negative"""
        if v < 0:
            raise ValueError('Counts must be non-negative')
        return v

    def __init__(self, **data):
        super().__init__(**data)
        # Generate ID if not provided
        if not self.id:
            self.id = self._generate_id()

    def _generate_id(self) -> str:
        """Generate unique ID based on timestamp and status"""
        timestamp = self.start_time.isoformat() if self.start_time else datetime.now().isoformat()
        content_to_hash = f"{timestamp}{self.status}{self.processed_chunks_count}{self.failed_chunks_count}"
        return hashlib.sha256(content_to_hash.encode()).hexdigest()

    @property
    def total_chunks_count(self) -> int:
        """Total number of chunks processed (success + failed)"""
        return self.processed_chunks_count + self.failed_chunks_count

    @property
    def success_rate(self) -> float:
        """Success rate as a percentage"""
        if self.total_chunks_count == 0:
            return 0.0
        return (self.processed_chunks_count / self.total_chunks_count) * 100